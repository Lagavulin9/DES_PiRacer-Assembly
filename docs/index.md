# Project 01: PiRacer


## Description
Assemble your own learning object - PiRacer


## Duration
40 hours / 1 week


## Experience Points
100


## Skills
* DIY
* HW Assembly
* Deep Learning
* Self Driving


## Forewords
### Learners’ Use of Learning Objects 
#### by Mohamed Ally, Martha Cleveland-Innes, Natasha Boskic, and Sandra Larwill
#### Conclusion
The integration of existing research, data analysis and interpretation suggest the following general conclusions. Learners require search information that is easy to understand. Their engagement is the keystone of any teaching-learning transaction; learning objects should provide active learning through hands-on activities and examples. As with all adult learning, learning objects should be relevant to applications that support work-related or personal goals. Accessibility and learner engagement in an object are important to learning. Identifying learning objectives in the search mechanisms of the objects so that learners can easily see the relevance of content to their needs will facilitate satisfaction with the search process and the use of the object. This supports knowledge transfer and the potential for reuse when knowledge transfer is incomplete.

These characteristics of the learning object search and the capacity for engagement influence the following outcomes. Learners are more likely to return to the repository and the object where these features exist and more likely to assign value to the repository and the object. These features will affect the extent to which the learner contextualizes and applies information. There is potential for the generation of new knowledge under these conditions.

Participants accessed the learning objects because they were asked to do so. However, most participants looked at a number of learning objects, not just one. This suggests an interest in either the process or the outcome of working with the learning object.

Much research on learning objects has focused on tagging and designing learning objects (Hamel & Ryan-Jones, 2002; Krauss & Ally, 2005; Metros, 2005; Petrinjak & Graham, 2005; Quinn, 2000). This research bridged the gap in the research by looking at learners’ experience with learning objects and their behavior when accessing them. Results from this study have many implications for educators who design and tag learning objects.

Learning objects must be designed with the learner in focus so that learners can access the objects easily and benefit from them. In course development, learning objects must be tied to course learning outcomes so that the learning experience relates back to the course (Ally, 2004). Also, learning objects must be designed for access as required and for immediate application. As indicated in this study, learners select learning objects that are related to the courses they are taking and to their current job.

Learning objects must be tagged properly to facilitate ease of access by learners and to provide learners with enough information to decide whether to work through a learning object. For the learners in this study, the title of the learning object was one criterion for deciding whether to retrieve and complete it. The title must reflect the content of the learning object and must be inviting.

The learner’s motivation level must be taken into consideration when developing learning objects. Perhaps various types of learning objects should be developed for varying motivation levels. For example, learners who are not motivated in a subject area could be prescribed a learning object to help them connect to the course content. This could motivate them to access other learning objects that are related to a course.

This study’s findings are limited to the group that participated in the study: customer service agents in a call center environment. This group has highly developed computer skills, and people in this occupation are accustomed to working independently with customers. Given the higher number of participants who completed pre- rather than post-surveys, results may have been biased by the requirement to complete surveys participants could neither reach the learning object nor close their browser without responding to the survey. This may have resulted in rushed, careless responses. Voluntary  articipation in the learning object assessment means the most interested and motivated were engaged; the general population might have found the  epositories less engaging.

Research on learners’ use of learning objects is currently limited. This study advanced current research and points toward more research needed in the following areas:
1. How much do learners transfer from the experience with the learning objects to practical, on the job situations?
2. Do learners with varying learning styles access varied learning objects, and what are their experiences with the learning objects?
3. How can learning objects be embedded with intelligence to adapt to learners needs?


## Introduction
PiRacer DonkeyCar — AI Autonomous Racing Robot Powered by Raspberry Pi 4, Deep Learning, Self Driving


## Objectives
* Assemble your PiRacer and make sure it is working as expected.


## Common Instructions
Safety first! Electronics is a potentially dangerous hobby. Any circuit that works with 120 VAC power from an electrical outlet is especially dangerous and could potentially kill you. Here are some safety guidelines to keep you safe as you work:
* Never work on a circuit while power is applied.
* Do not connect power to a circuit until the circuit is finished and you have carefully checked your work.
* If you smell anything burning, immediately disconnect the power and examine your circuit to find out what went wrong.
* Keep your work area dry.
* Always wear safety goggles.
* Be careful around large capacitors; they can continue to hold voltage long after they are disconnected from power.
* Be especially careful when you solder because a hot soldering iron can easily burn you.
* Always work in a well-ventilated space.
* Have safety equipment such as a fire extinguisher, a first-aid kit, and a phone nearby.

### PiRacer Assembly Manual
#### Screws/standoffs diagram
To let you find the screws easily, we make this diagram for reference. Note that the screws come with servo wheel and cooling fan are not listed here.

![Jetracer-assembly-20.png](/docs/assets/images/Jetracer-assembly-20.png)

1. Fixing the motors to metal chassis with screw M3\*6. **Note that you cannot replace the M3*6 screws by longer screw, otherwise the motor cannot work.**

![Jetracer-assembly-1.png](/docs/assets/images/Jetracer-assembly-1.png)

2. Put the coupler to wheels. You may need to hit it into the wheel by tools and fix it by M4\*8 screw.

![Jetracer-assembly-2.png](/docs/assets/images/Jetracer-assembly-2.png)

3. Assemble the wheels. Turn it tightly with the Black screw. You should turn the screw by the longer side of the little spanner.
![Jetracer-assembly-3.png](/docs/assets/images/Jetracer-assembly-3.png)

4. Mount the servo holder on metal chassis.

![Jetracer-assembly-4.png](/docs/assets/images/Jetracer-assembly-4.png)

5. Set servo on the holder and fix it by screws and nuts. Please make sure that you put the sever in the correct way.

![Jetracer-assembly-5.png](/docs/assets/images/Jetracer-assembly-5.png)

6. When you assemble the servo pull bar, please refer to the image below carefully. The pull bar is combined by two small ball joint and the short bar, Note that the two small ball should be perpendicular to each other. Fix servo wheel to the servo wheel holder by its own screws. Then fix the screw pull bar (the flat side) on the servo wheel holder by M2.5\*12 screw and M2.5 locknut.**Note that the groove of the servo wheel is toward outside.**

![Jetracer-assembly-6.png](/docs/assets/images/Jetracer-assembly-6.png)

7. Assemble the front-wheel pull bar. The front-wheel pull bard is combined by two bard joint (big) and the long bar. Then put the bearings in steering knuckle.

![Jetracer-assembly-8.png](/docs/assets/images/Jetracer-assembly-8.png)

8. Together the servo pull bard, front-wheel pull bard, and steering knuckles. The servo pull bar in on the top, and then the front-wheel pull bard, finally the knuckles. The bigger bearing should toward inside. **Please refer to the image below carefully.**

![Jetracer-assembly-9.png](/docs/assets/images/Jetracer-assembly-9.png)

9. Fix wheel on the steering knuckle by M4 screws and locknut. **Note that you cannot fix the wheel too tight or too loose. Please test if the wheel can run smoothly after fixing.**

![Jetracer-assembly-10.png](/docs/assets/images/Jetracer-assembly-10.png)

10. Set M3 standoffs for the front wheels.

![Jetracer-assembly-7.png](/docs/assets/images/Jetracer-assembly-7.png)

11. Assemble the front-wheels combination. Put the servo wheel to servo, fix it by M3 screw. Fix the wheels by M2 screws and locknut and the triangle board.

![Jetracer-assembly-18.png](/docs/assets/images/Jetracer-assembly-18.png)

12. Put standoffs for PiRacer expansion board and bumper. Put the EVA felt pad.

![Jetracer-assembly-19.png](/docs/assets/images/Jetracer-assembly-19.png)

13. Set camera holder and antenna on PiRacer Expansion board, note that refer to the image below about the direction.

![Jetracer-assembly-11.png](/docs/assets/images/Jetracer-assembly-11.png)

14. Assemble batteries in the correct direction. Connect wires of motor and servo to PiRacer Expansion board.

![Jetracer-assembly-12.png](/docs/assets/images/Jetracer-assembly-12.png)

15. Adjust the place of wires then fix PiRacer Expansion board on metal chassis. Fix the metal bumper by M3 screws.

![Jetracer-assembly-13.png](/docs/assets/images/Jetracer-assembly-13.png)

16. Put the Raspberry Pi and fix.
17. Mount camera to its holder by nylon screws. **Note that the Acrylic board should be put between camera and the metal holder to avoid shorting.** Set the 3D-printed motor enclosure on motors. Connect the Raspberry Pi to PiRacer Expansion board by 6PIN wires. **You should connect 5V to 5V, 3.3V to 3.3V, please take care about it.**

### Setup Raspberry-Pi
#### Step 1. Install libraries

Please make sure that you have install image and it could start normally. Open terminal and install libraries as below

<pre>sudo apt-get update
sudo apt-get upgrade
sudo apt-get install build-essential python3 python3-dev python3-pip python3-virtualenv python3-numpy python3-picamera 
sudo apt-get install python3-pandas python3-rpi.gpio i2c-tools avahi-utils joystick libopenjp2-7-dev libtiff5-dev gfortran 
sudo apt-get install libatlas-base-dev libopenblas-dev libhdf5-serial-dev git ntp
</pre>

#### Step 2. Install libraries for OpenCV

<pre>sudo apt-get install libilmbase-dev libopenexr-dev libgstreamer1.0-dev libjasper-dev libwebp-dev 
sudo apt-get install libatlas-base-dev libavcodec-dev libavformat-dev libswscale-dev libqtgui4 libqt4-test
</pre>

#### Step 3. Setup virtual environment

<pre>python3 -m virtualenv -p python3 env --system-site-packages
echo "source env/bin/activate" >> ~/.bashrc
source ~/.bashrc
</pre>

Note: Here we modify .bashrc for auto-entering the virtual environment, if you want to back to normal environment, please use command deactivate.

#### Step 4. Install Donkeycar Python codes

*   Create project directory

<pre>mkdir projects
cd ~/projects
</pre>

*   Clone donkeycar codes from Github (Use the commands of next one if you buy the pro version)

<pre>git clone https://github.com/waveshare/donkeycar
cd donkeycar
git checkout master
pip install -e .[pi]
pip install tensorflow==1.13.1
pip install numpy --upgrade
</pre>

*   <font color="red">If the version you buy is Piracer Pro Kit. Please use the following commands instead.</font>

<pre>git clone https://github.com/autorope/donkeycar
cd donkeycar
git checkout master
pip install -e .[pi]
pip install tensorflow==1.13.1
pip install numpy --upgrade
</pre>

*   Check if you have install tensorflow successfully

<pre>python -c "import tensorflow"
</pre>

*   It is normal that if you get wronging as below

<pre>/home/pi/env/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.4 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5
  return f(*args, **kwds)
/home/pi/env/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: builtins.type size changed, may indicate binary incompatibility. Expected 432, got 412
  return f(*args, **kwds)
</pre>

#### Step 5. Install OpenCV

*   Install OpenCV

<pre>sudo apt install python3-opencv
</pre>

*   If you fail at the last command, please use this command to install OpenCV again

<pre>pip install opencv-python
</pre>

*   Check if the OpenCV is installed successfully

<pre>python -c "import cv2"
</pre>

#### Step 6. Install Service of OLED Display

*   Use command belows to install service for OLED displaying. The OLED onboard can be used to display IP address, Voltage and current, etc.

<pre>cd ~
git clone https://github.com/waveshare/pi-display
cd pi-display
sudo ./install.sh
</pre>

#### Step 7. Create DonkeyCar

*   Create donkeycar example

<pre>donkey createcar --path ~/mycar
</pre>

After runing, files will be generated and saved in the directly ~/mycar

### Install Linux PC

*   Install Ubuntu 18.04 LTS in your PC (Virtual)
*   Open termnial and install minconda Python 3.7 64bit

<pre>wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh
bash ./Miniconda3-latest-Linux-x86_64.sh
</pre>

*   Create directory for project

<pre>mkdir projects
cd projects
</pre>

*   Clone souce codes of DonkeyCar from Github

<pre>git clone https://github.com/waveshare/donkeycar
cd donkeycar
git checkout master
</pre>

*   If you are not the first time to install Donkey, please update Conda and remove the old donkey

<pre>conda update -n base -c defaults conda
conda env remove -n donkey
</pre>

*   Build anaconda environment

<pre>conda env create -f install/envs/ubuntu.yml
conda activate donkey
pip install -e .[pc]
</pre>

*   Install Tensorflow

Note: Herein we use the Tensorflow CPU version.

<pre>conda install tensorflow==1.13.1
</pre>

*   Create local directory

<pre>donkey createcar --path ~/mycar
</pre>

Note:Re-Open the terminal and run **conda activate donkey** command to enter the donkey virtual

### WEB Controlling

*   Open the terminal and run the follow commands:

<pre>[[email protected]](/cdn-cgi/l/email-protection):~$ source ~/env/bin/activate
(env) [[email protected]](/cdn-cgi/l/email-protection):~$ cd mycar/
(env) [[email protected]](/cdn-cgi/l/email-protection):~/mycar$ python manage.py drive
</pre>

Note that you cannot use sudo in front of the command python manage.py drive, otherwise it cannot be run successfully.

*   Open the Chrome in host pc and go to https://<raspberrypi_ip_address>:8887 which is the WEB control page of Donkeycar

![DonkeyCar for Jetson Nano 3-1.png](/docs/assets/images/DonkeyCar_for_Jetson_Nano_3-1.png)

Choose the Max speed for the Max Throttle option. Click the right joystick windows and drag it to move the PiRacer. The Angle & Throttle bars will display the steering angle and the motor speed. You can click the Start Recording button to capture images and save to path ~/mycar/data

*   You can also go into the WEB page by your smartphone or tablet.

![DonkeyCar for Jetson Nano 3-2.png](/docs/assets/images/DonkeyCar_for_Jetson_Nano_3-2.png)

*   You can also control the car by keyboard

Space: Stop Moving/Recording
R: Recording
I: Speed up
K: Slow down
J: Turn left
L: Turn right


### Calibrate DonkeyCar

To make sure that the Donkeycar can turn around successfully, you need to calibrate the car both in hardware and software.

Keep the front wheels forward when assembling. You need to adjust the length of the pull-bars.

![DonkeyCar for Jetson Nano 4-1.png](/docs/assets/images/DonkeyCar_for_Jetson_Nano_4-1.png)

Adjust the steering servo

![DonkeyCar for Jetson Nano 4-2.png](/docs/assets/images/DonkeyCar_for_Jetson_Nano_4-2.png)

Open the terminal and use commands to calibrate

<pre>cd ~/mycar
donkey calibrate --channel 0 --bus=1
</pre>

Type value 360 (or 300, 400) to check if the steering servo turns

![DonkeyCar for Jetson Nano 4-3.png](/docs/assets/images/DonkeyCar_for_Jetson_Nano_4-3.png)

Adjust the value to make the servo turns to the center place (keep forward) and remember the value. For example, if the value 330 could work and let the servo keep in the center, you can test if 230 and 430 can let the servo turns to the far left and the far right.

Then Once you get the far left data and the far-right data, you can modify the config.py file and change the STEERING_LEFT_PWM and STEERING_RIGHT_PWM.

![DonkeyCar for Jetson Nano 4-6.png](/docs/assets/images/DonkeyCar_for_Jetson_Nano_4-6.png)

Note that you cannot set the angle in which the steering servo turns too big or too small. You can adjust it as below (far right)

![DonkeyCar for Jetson Nano 4-4.png](/docs/assets/images/DonkeyCar_for_Jetson_Nano_4-4.png)

Finally, check if the throttle is set correctly as below

![DonkeyCar for Jetson Nano 4-7.png](/docs/assets/images/DonkeyCar_for_Jetson_Nano_4-7.png)

### Teleoperation

Open file ~/mycar/confgi.py and find the blow part. Check if the CONTROLLER_TYPE is set as Xbox

![DonkeyCar for Jetson Nano 5-1.png](/docs/assets/images/DonkeyCar_for_Jetson_Nano_5-1.png)

Connect the USB adapter of Gamepad to Raspberry Pi

Open a terminal and run the following commands:

<pre>cd ~/mycar
python manage.py drive --js
</pre>

If you want to enable the gamepad control by default, you can modify the config.py file, set USE_JOYSTICK_AS_DEFAULT to True.

Note

*   Left joystick - Turn left/right
*   Right joystick - Speed up (push-up)
*   Right joystick - Speed down (pull-down twice)
*   It will auto-record the driving data if the throttle is not 0
*   Triangle - Speed up
*   X - Speed down

## Mandatory part
* Your PiRacer must be working and must be drivable using the WEB and gamepad controller.


## Bonus part
* Try Deep Learning and Self Driving mode on your PiRacer using DonkeyCar


## Submission & Peer evaluation
How to do peer evaluation
